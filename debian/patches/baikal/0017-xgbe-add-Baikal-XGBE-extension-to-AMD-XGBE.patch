From 9632ccd0da8487f1ba721a155a7a9d0f82a3f251 Mon Sep 17 00:00:00 2001
From: Roman Stavtsev <roman.stavtsev@baikalelectronics.ru>
Date: Sat, 17 Apr 2021 16:09:13 +0300
Subject: [PATCH 017/106] xgbe: add Baikal XGBE extension to AMD XGBE

---
 drivers/net/ethernet/amd/Kconfig              |   7 +
 drivers/net/ethernet/amd/xgbe/Makefile        |   1 +
 drivers/net/ethernet/amd/xgbe/baikal-mdio.c   | 635 ++++++++++++++++++
 drivers/net/ethernet/amd/xgbe/xgbe-desc.c     |   5 +
 drivers/net/ethernet/amd/xgbe/xgbe-dev.c      |   4 +
 drivers/net/ethernet/amd/xgbe/xgbe-drv.c      | 117 +++-
 drivers/net/ethernet/amd/xgbe/xgbe-main.c     |  22 +-
 drivers/net/ethernet/amd/xgbe/xgbe-platform.c |  41 ++
 drivers/net/ethernet/amd/xgbe/xgbe.h          |  23 +
 9 files changed, 852 insertions(+), 3 deletions(-)
 create mode 100644 drivers/net/ethernet/amd/xgbe/baikal-mdio.c

diff --git a/drivers/net/ethernet/amd/Kconfig b/drivers/net/ethernet/amd/Kconfig
index d0b0609bbe23..8e391c23b82c 100644
--- a/drivers/net/ethernet/amd/Kconfig
+++ b/drivers/net/ethernet/amd/Kconfig
@@ -194,4 +194,11 @@ config AMD_XGBE_HAVE_ECC
 	bool
 	default n
 
+config BAIKAL_XGBE
+	bool "Baikal XGBE support"
+	default n
+	depends on AMD_XGBE
+	help
+	  Say Y to enable Baikal XGBE support
+
 endif # NET_VENDOR_AMD
diff --git a/drivers/net/ethernet/amd/xgbe/Makefile b/drivers/net/ethernet/amd/xgbe/Makefile
index 620785ffbd51..24e21b66dd14 100644
--- a/drivers/net/ethernet/amd/xgbe/Makefile
+++ b/drivers/net/ethernet/amd/xgbe/Makefile
@@ -7,6 +7,7 @@ amd-xgbe-objs := xgbe-main.o xgbe-drv.o xgbe-dev.o \
 		 xgbe-i2c.o xgbe-phy-v1.o xgbe-phy-v2.o \
 		 xgbe-platform.o
 
+amd-xgbe-$(CONFIG_BAIKAL_XGBE) += baikal-mdio.o
 amd-xgbe-$(CONFIG_PCI) += xgbe-pci.o
 amd-xgbe-$(CONFIG_AMD_XGBE_DCB) += xgbe-dcb.o
 amd-xgbe-$(CONFIG_DEBUG_FS) += xgbe-debugfs.o
diff --git a/drivers/net/ethernet/amd/xgbe/baikal-mdio.c b/drivers/net/ethernet/amd/xgbe/baikal-mdio.c
new file mode 100644
index 000000000000..e671e247423c
--- /dev/null
+++ b/drivers/net/ethernet/amd/xgbe/baikal-mdio.c
@@ -0,0 +1,635 @@
+/*
+ *
+ * This file is available to you under your choice of the following two
+ * licenses:
+ *
+ * License 1: GPLv2
+ *
+ * Copyright (c) 2014 Advanced Micro Devices, Inc.
+ *
+ * This file is free software; you may copy, redistribute and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 2 of the License, or (at
+ * your option) any later version.
+ *
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ * This file incorporates work covered by the following copyright and
+ * permission notice:
+ *     The Synopsys DWC ETHER XGMAC Software Driver and documentation
+ *     (hereinafter "Software") is an unsupported proprietary work of Synopsys,
+ *     Inc. unless otherwise expressly agreed to in writing between Synopsys
+ *     and you.
+ *
+ *     The Software IS NOT an item of Licensed Software or Licensed Product
+ *     under any End User Software License Agreement or Agreement for Licensed
+ *     Product with Synopsys or any supplement thereto.  Permission is hereby
+ *     granted, free of charge, to any person obtaining a copy of this software
+ *     annotated with this license and the Software, to deal in the Software
+ *     without restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ *     of the Software, and to permit persons to whom the Software is furnished
+ *     to do so, subject to the following conditions:
+ *
+ *     The above copyright notice and this permission notice shall be included
+ *     in all copies or substantial portions of the Software.
+ *
+ *     THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ *     BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
+ *     TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
+ *     PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS
+ *     BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ *     CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ *     SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ *     INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ *     ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ *     THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *
+ * License 2: Modified BSD
+ *
+ * Copyright (c) 2014 Advanced Micro Devices, Inc.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Advanced Micro Devices, Inc. nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * This file incorporates work covered by the following copyright and
+ * permission notice:
+ *     The Synopsys DWC ETHER XGMAC Software Driver and documentation
+ *     (hereinafter "Software") is an unsupported proprietary work of Synopsys,
+ *     Inc. unless otherwise expressly agreed to in writing between Synopsys
+ *     and you.
+ *
+ *     The Software IS NOT an item of Licensed Software or Licensed Product
+ *     under any End User Software License Agreement or Agreement for Licensed
+ *     Product with Synopsys or any supplement thereto.  Permission is hereby
+ *     granted, free of charge, to any person obtaining a copy of this software
+ *     annotated with this license and the Software, to deal in the Software
+ *     without restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+ *     of the Software, and to permit persons to whom the Software is furnished
+ *     to do so, subject to the following conditions:
+ *
+ *     The above copyright notice and this permission notice shall be included
+ *     in all copies or substantial portions of the Software.
+ *
+ *     THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ *     BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
+ *     TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
+ *     PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS
+ *     BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ *     CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ *     SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ *     INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ *     CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ *     ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ *     THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/kmod.h>
+#include <linux/mdio.h>
+#include <linux/phy.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/of_device.h>
+#include <linux/of_mdio.h>
+#include <linux/bitops.h>
+#include <linux/jiffies.h>
+#include <linux/clk.h>
+
+#include "xgbe.h"
+#include "xgbe-common.h"
+
+#ifndef VR_XS_PMA_MII_Gen5_MPLL_CTRL
+#define VR_XS_PMA_MII_Gen5_MPLL_CTRL                    0x807A
+#endif
+#define VR_XS_PMA_MII_Gen5_MPLL_CTRL_REF_CLK_SEL_bit    (1 << 13)
+#define VR_XS_PCS_DIG_CTRL1                             0x8000
+#define VR_XS_PCS_DIG_CTRL1_VR_RST_Bit                  MDIO_CTRL1_RESET
+#define SR_XC_or_PCS_MMD_Control1                       MDIO_CTRL1
+#define SR_XC_or_PCS_MMD_Control1_RST_Bit               MDIO_CTRL1_RESET
+#define DWC_GLBL_PLL_MONITOR                            0x8010
+#define SDS_PCS_CLOCK_READY_mask                        0x1C
+#define SDS_PCS_CLOCK_READY_bit                         0x10
+#define VR_XS_PMA_MII_ENT_GEN5_GEN_CTL                  0x809C
+#define VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LANE_MODE_KX4    (4 << 0)
+#define VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LANE_MODE_MASK   0x0007
+#define VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LINK_WIDTH_4     (2 << 8)
+#define VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LINK_WIDTH_MASK  0x0700
+#define VR_XS_OR_PCS_MMD_DIGITAL_CTL1_VR_RST            (1 << 15)
+
+#define DELAY_COUNT     50
+
+static int be_xgbe_an_restart_kr_training(struct xgbe_prv_data *pdata)
+{
+	int reg = 0;
+
+	DBGPR("%s\n", __FUNCTION__);
+
+	/* Restart training */
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, 0x0096, 3);
+	msleep(500);
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, 0x0096, 1);
+	
+	/* The worse case when training continue till 500ms */
+	msleep(500);
+
+	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, 0x0097);
+	/* Check training failure */
+	if (reg & (1 << 3))
+		return -1;
+
+	/* Success */
+	return 0;
+}
+
+static int be_xgbe_an_enable_kr_training(struct xgbe_prv_data *pdata)
+{
+	DBGPR("%s\n", __FUNCTION__);
+	
+	/* Enable training */
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, 0x0096, 2);
+	
+	return 0;
+}
+
+static int be_xgbe_phy_pcs_power_cycle(struct xgbe_prv_data *pdata)
+{
+	int ret;
+	DBGPR("%s\n", __FUNCTION__);
+
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+
+	ret |= MDIO_CTRL1_LPOWER;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, ret);
+
+	usleep_range(75, 100);
+
+	ret &= ~MDIO_CTRL1_LPOWER;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, ret);
+
+	return 0;
+}
+
+static int be_xgbe_phy_xgmii_mode_kx4(struct xgbe_prv_data *pdata)
+{
+	int  ret, count;
+
+	DBGPR_MDIO("%s\n", __FUNCTION__);
+
+	/* Write 2'b01 to Bits[1:0] of SR PCS Control2 to set the xpcx_kr_0
+	 * output to 0.
+	 */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+
+	ret &= ~MDIO_PCS_CTRL2_TYPE;
+	ret |= MDIO_PCS_CTRL2_10GBX;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL2, ret);
+
+	/* Set Bit 13 SR PMA MMD Control1 Register (for back plane) to 1. */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_CTRL1);
+
+	ret |= 0x2000;
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, MDIO_CTRL1, ret);
+
+	/* Set LANE_MODE TO KX4 (4). */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_ENT_GEN5_GEN_CTL);
+
+	ret &= ~VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LANE_MODE_MASK;
+	ret |= VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LANE_MODE_KX4;
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_ENT_GEN5_GEN_CTL, ret);
+
+	/* Set LANE_WIDTH (2) 4 lanes per link. */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_ENT_GEN5_GEN_CTL);
+
+	ret &= ~VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LINK_WIDTH_MASK;
+	ret |= VR_XS_PMA_MII_ENT_GEN5_GEN_CTL_LINK_WIDTH_4;
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_ENT_GEN5_GEN_CTL, ret);
+
+	/* Initiate Software Reset. */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1);
+
+	ret |= VR_XS_OR_PCS_MMD_DIGITAL_CTL1_VR_RST;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1, ret);
+
+	/* Wait until reset done. */
+	count = DELAY_COUNT;
+	do {
+		msleep(20);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1);
+	} while (!!(ret & VR_XS_OR_PCS_MMD_DIGITAL_CTL1_VR_RST) && --count);
+
+	if (ret & VR_XS_OR_PCS_MMD_DIGITAL_CTL1_VR_RST)
+		return -ETIMEDOUT;
+
+	return 0;
+}
+
+static int be_xgbe_phy_xgmii_mode_kr(struct xgbe_prv_data *pdata)
+{
+	int ret;
+	DBGPR("%s\n", __FUNCTION__);
+	
+	/* Enable KR training */
+	ret = be_xgbe_an_enable_kr_training(pdata);
+	if (ret < 0)
+		return ret;
+
+	/* Set PCS to KR/10G speed */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+
+	ret &= ~MDIO_PCS_CTRL2_TYPE;
+	ret |= MDIO_PCS_CTRL2_10GBR;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL2, ret);
+
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+
+	ret &= ~MDIO_CTRL1_SPEEDSEL;
+	ret |= MDIO_CTRL1_SPEED10G;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, ret);
+
+	ret = be_xgbe_phy_pcs_power_cycle(pdata);
+	if (ret < 0)
+    		return ret;
+
+	return 0;
+}
+
+static int be_xgbe_phy_xgmii_mode(struct xgbe_prv_data *pdata)
+{
+    struct device *dev = pdata->dev;
+    char mode[32];
+    const char *pm = mode;
+
+    if(!of_property_read_string(dev->of_node, "be,pcs-mode", &pm)) {
+        if(strcasecmp(pm, "KX4") == 0){
+            DBGPR("xgbe: mode KX4 = 0x%X function: %s\n", mode, __FUNCTION__);
+            return be_xgbe_phy_xgmii_mode_kx4(pdata);
+        }
+    }
+
+    DBGPR("xgbe: mode KR = 0x%X function: %s\n", mode, __FUNCTION__);
+
+    return be_xgbe_phy_xgmii_mode_kr(pdata);
+}
+
+static int __maybe_unused be_xgbe_phy_soft_reset(struct xgbe_prv_data *pdata)
+{
+	int count, ret;
+	DBGPR("%s\n", __FUNCTION__);
+
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+
+	ret |= MDIO_CTRL1_RESET;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, ret);
+
+	count = DELAY_COUNT;
+	do {
+		msleep(20);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+		if (ret < 0)
+			return ret;
+	} while ((ret & MDIO_CTRL1_RESET) && --count);
+
+	if (ret & MDIO_CTRL1_RESET)
+		return -ETIMEDOUT;
+
+	return 0;
+}
+
+static int be_xgbe_phy_config_aneg(struct xgbe_prv_data *pdata)
+{
+	int reg;
+
+	DBGPR("%s\n", __FUNCTION__);
+
+	pdata->link_check = jiffies;
+	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_CTRL1);
+	
+	/* Disable auto negotiation in any case! */
+	reg &= ~MDIO_AN_CTRL1_ENABLE;
+	pdata->phy.autoneg = AUTONEG_DISABLE;
+
+	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_CTRL1, reg);
+
+	return 0;
+}
+
+static int ext_phy_probe(struct device *pdev, struct phy_device **phy_dev)
+{
+        struct device_node *xmit_node;
+        struct phy_device *phydev;
+        struct device *dev = pdev;
+        int ret;
+
+        /* Retrieve the xmit-handle */
+        xmit_node = of_parse_phandle(dev->of_node, "ext-phy-handle", 0);
+        if (!xmit_node)
+                return -ENODEV;
+
+        phydev = of_phy_find_device(xmit_node);
+        if (!phydev)
+                return -ENODEV;
+
+        ret = phy_init_hw(phydev);
+        if (ret < 0)
+                return ret;
+
+        if ((phydev->speed != SPEED_10000) && (phydev->duplex != DUPLEX_FULL))
+        	return -ENODEV;
+
+        *phy_dev = phydev;
+
+        return 0;
+}
+
+int be_xgbe_phy_config_init(struct xgbe_prv_data *pdata)
+{
+	int ret = 0;
+    	int count = DELAY_COUNT;
+	DBGPR("%s\n", __FUNCTION__);
+
+        if(ext_phy_probe(&pdata->platdev->dev, &pdata->phydev)) {
+                pr_info("XGMAC: can't probe external PHY\n");
+                return 1;
+        }
+
+        pr_info("XGMAC: probe external PHY with success\n");
+
+	/* Initialize supported features */
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_10000baseT_Full_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_10000baseKX4_Full_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_10000baseKR_Full_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_Backplane_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_Autoneg_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_Asym_Pause_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_mod_bit(ETHTOOL_LINK_MODE_Pause_BIT,
+			pdata->phydev->supported, 1);
+	linkmode_copy(pdata->phydev->advertising, pdata->phydev->supported);
+
+	pdata->phy.pause_autoneg = 0;
+	pdata->phy.tx_pause = 0;
+	pdata->phy.rx_pause = 0;
+	
+        /* Switch XGMAC PHY PLL to use external ref clock from pad */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_Gen5_MPLL_CTRL);
+	ret &= ~(VR_XS_PMA_MII_Gen5_MPLL_CTRL_REF_CLK_SEL_bit);
+	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, VR_XS_PMA_MII_Gen5_MPLL_CTRL, ret);
+	wmb();
+
+	/* Make vendor specific soft reset */
+	ret = XMDIO_READ(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1);
+	ret |= VR_XS_PCS_DIG_CTRL1_VR_RST_Bit;
+	XMDIO_WRITE(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1, ret);
+	wmb();
+
+	/* Wait reset finish */
+	count = DELAY_COUNT;
+	do {
+		usleep_range(500, 600);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, VR_XS_PCS_DIG_CTRL1);
+	} while(((ret & VR_XS_PCS_DIG_CTRL1_VR_RST_Bit) != 0) && count--);
+
+
+	DBGPR("%s %x\n", __FUNCTION__, ret);
+	/*
+	 * Wait for the RST (bit 15) of the “SR XS or PCS MMD Control1” Register is 0.
+	 * This bit is self-cleared when Bits[4:2] in VR XS or PCS MMD Digital
+	 * Status Register are equal to 3’b100, that is, Tx/Rx clocks are stable
+	 * and in Power_Good state.
+	 */
+	count = DELAY_COUNT;
+	do {
+		usleep_range(500, 600);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, SR_XC_or_PCS_MMD_Control1);
+	} while(((ret & SR_XC_or_PCS_MMD_Control1_RST_Bit) != 0) && count--);
+
+	/*
+	 * This bit is self-cleared when Bits[4:2] in VR XS or PCS MMD Digital
+	 * Status Register are equal to 3’b100, that is, Tx/Rx clocks are stable
+	 * and in Power_Good state.
+	 */
+	count = DELAY_COUNT;
+	do {
+		usleep_range(500, 600);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, DWC_GLBL_PLL_MONITOR);
+	} while(((ret & SDS_PCS_CLOCK_READY_mask) != SDS_PCS_CLOCK_READY_bit) && count-- );
+
+	/* Turn off and clear interrupts */
+	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INTMASK, 0);
+	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, 0);
+	wmb();
+
+	be_xgbe_phy_config_aneg(pdata);
+
+	ret = be_xgbe_phy_xgmii_mode(pdata);
+    
+	count = DELAY_COUNT;
+	do
+	{
+		msleep(10);
+		ret = XMDIO_READ(pdata, MDIO_MMD_PCS, 0x0001);
+	} while(((ret & 0x0004) != 0x0004) && count--);
+
+	return 0;
+}
+
+static int be_xgbe_phy_aneg_done(struct xgbe_prv_data *pdata)
+{
+	int reg;
+	DBGPR("%s\n", __FUNCTION__);
+
+	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_STAT1);
+
+	return (reg & MDIO_AN_STAT1_COMPLETE) ? 1 : 0;
+}
+
+static int be_xgbe_phy_update_link(struct xgbe_prv_data *pdata)
+{
+	int new_state = 0;
+	int ret = 0;
+	struct phy_device *phydev;
+
+	if(!pdata || !pdata->phydev)
+	    return 1;
+
+	phydev = pdata->phydev;
+	ret = phy_read_mmd(phydev, MDIO_MMD_PHYXS, 0x1001);
+
+	if (pdata->phy.link) {
+		/* Flow control support */
+		pdata->pause_autoneg = pdata->phy.pause_autoneg;
+
+		if (pdata->tx_pause != pdata->phy.tx_pause) {
+			new_state = 1;
+			pdata->hw_if.config_tx_flow_control(pdata);
+			pdata->tx_pause = pdata->phy.tx_pause;
+		}
+
+		if (pdata->rx_pause != pdata->phy.rx_pause) {
+			new_state = 1;
+			pdata->hw_if.config_rx_flow_control(pdata);
+			pdata->rx_pause = pdata->phy.rx_pause;
+		}
+
+		/* Speed support */
+		if (pdata->phy_speed != pdata->phy.speed) {
+			new_state = 1;
+			pdata->phy_speed = pdata->phy.speed;
+		}
+
+		if (pdata->phy_link != pdata->phy.link) {
+			new_state = 1;
+			pdata->phy_link = pdata->phy.link;
+		}
+	} else if (pdata->phy_link) {
+		new_state = 1;
+		pdata->phy_link = 0;
+		pdata->phy_speed = SPEED_UNKNOWN;
+	}
+
+	return 0;
+}
+
+static void be_xgbe_phy_read_status(struct xgbe_prv_data *pdata)
+{
+	int reg, link_aneg;
+	
+	if (!pdata->phydev)
+		return;
+
+	pdata->phy.link = 1;
+
+	if (test_bit(XGBE_LINK_ERR, &pdata->dev_state)) {
+		netif_carrier_off(pdata->netdev);
+
+		pdata->phy.link = 0;
+		goto update_link;
+	}
+
+	link_aneg = (pdata->phy.autoneg == AUTONEG_ENABLE);
+
+	if (pdata->phydev) {
+		pdata->phydev->drv->read_status(pdata->phydev);
+		/* Pop out old values */
+		pdata->phydev->drv->read_status(pdata->phydev);
+		if (!pdata->phydev->link){
+			pdata->phydev->link = 0;
+			pdata->phy.link &= pdata->phydev->link;
+		}
+	}
+	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1);
+	pdata->phy.link &= (reg & MDIO_STAT1_LSTATUS) ? 1 : 0;
+
+	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_STAT1);
+	pdata->phy.link &= (reg & MDIO_STAT1_LSTATUS) ? 1 : 0;
+
+	if (pdata->phy.link) {
+		if (link_aneg && !be_xgbe_phy_aneg_done(pdata)) {
+			return;
+		}
+
+		if (test_bit(XGBE_LINK_INIT, &pdata->dev_state))
+			clear_bit(XGBE_LINK_INIT, &pdata->dev_state);
+
+		netif_carrier_on(pdata->netdev);
+	} else {
+		if (test_bit(XGBE_LINK_INIT, &pdata->dev_state)) 
+			if (link_aneg)
+				return;
+
+		netif_carrier_off(pdata->netdev);
+
+		/* If KX4 mode is enabled training doesn't affect behavior */
+		be_xgbe_an_restart_kr_training(pdata);
+		/* Pop out old values */
+		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1);
+		XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_STAT1);
+	}
+
+update_link:
+	be_xgbe_phy_update_link(pdata);
+}
+
+static void be_xgbe_phy_stop(struct xgbe_prv_data *pdata)
+{
+	netif_dbg(pdata, link, pdata->netdev, "stopping PHY\n");
+
+	/* Disable auto-negotiation interrupts */
+	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INTMASK, 0);
+
+	pdata->phy.link = 0;
+	netif_carrier_off(pdata->netdev);
+
+	be_xgbe_phy_update_link(pdata);
+}
+
+/**
+ * be_xgbe_phy_start() - dummy
+ */
+int be_xgbe_phy_start(struct xgbe_prv_data *pdata)
+{
+        return 0;
+}
+
+/**
+ * be_xgbe_phy_exit() - dummy
+ */
+void be_xgbe_phy_exit(struct xgbe_prv_data *pdata)
+{
+	return;
+}
+
+/**
+ * be_an_isr() - dummy
+ */
+irqreturn_t be_an_isr(struct xgbe_prv_data *pdata)
+{
+	return IRQ_HANDLED;
+}
+
+void xgbe_init_function_ptrs_phy_baikal(struct xgbe_phy_if *phy_if)
+{
+	phy_if->phy_init        = be_xgbe_phy_config_init;
+	phy_if->phy_exit	= be_xgbe_phy_exit;
+	phy_if->phy_reset       = be_xgbe_phy_soft_reset;
+	phy_if->phy_stop        = be_xgbe_phy_stop;
+	phy_if->phy_status      = be_xgbe_phy_read_status;
+	phy_if->phy_config_aneg = be_xgbe_phy_config_aneg;
+	phy_if->phy_start	= be_xgbe_phy_start;
+	phy_if->an_isr		= be_an_isr;
+}
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-desc.c b/drivers/net/ethernet/amd/xgbe/xgbe-desc.c
index 230726d7b74f..ebd1985c3614 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-desc.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-desc.c
@@ -366,8 +366,13 @@ static int xgbe_map_rx_buffer(struct xgbe_prv_data *pdata,
 	}
 
 	if (!ring->rx_buf_pa.pages) {
+#ifdef CONFIG_BAIKAL_XGBE
+		ret = xgbe_alloc_pages(pdata, &ring->rx_buf_pa,
+				       0, ring->node);
+#else
 		ret = xgbe_alloc_pages(pdata, &ring->rx_buf_pa,
 				       PAGE_ALLOC_COSTLY_ORDER, ring->node);
+#endif
 		if (ret)
 			return ret;
 	}
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index d5fd49dd25f3..adf3ee7fcde9 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@ -689,7 +689,9 @@ static void xgbe_enable_dma_interrupts(struct xgbe_prv_data *pdata)
 			 *          per channel interrupts in edge triggered
 			 *          mode)
 			 */
+#ifndef CONFIG_BAIKAL_XGBE
 			if (!pdata->per_channel_irq || pdata->channel_irq_mode)
+#endif
 				XGMAC_SET_BITS(channel->curr_ier,
 					       DMA_CH_IER, TIE, 1);
 		}
@@ -701,7 +703,9 @@ static void xgbe_enable_dma_interrupts(struct xgbe_prv_data *pdata)
 			 *          mode)
 			 */
 			XGMAC_SET_BITS(channel->curr_ier, DMA_CH_IER, RBUE, 1);
+#ifndef CONFIG_BAIKAL_XGBE
 			if (!pdata->per_channel_irq || pdata->channel_irq_mode)
+#endif
 				XGMAC_SET_BITS(channel->curr_ier,
 					       DMA_CH_IER, RIE, 1);
 		}
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index 4f714f874c4f..4654cd2ceca9 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@ -216,8 +216,15 @@ static int xgbe_alloc_channels(struct xgbe_prv_data *pdata)
 		channel->node = node;
 		cpumask_set_cpu(cpu, &channel->affinity_mask);
 
+#ifndef CONFIG_BAIKAL_XGBE
 		if (pdata->per_channel_irq)
 			channel->dma_irq = pdata->channel_irq[i];
+#else
+		if (pdata->per_channel_irq) {
+			channel->tx_dma_irq = pdata->channel_tx_irq[i];
+			channel->rx_dma_irq = pdata->channel_rx_irq[i];
+		}
+#endif
 
 		if (i < pdata->tx_ring_count) {
 			ring = xgbe_alloc_node(sizeof(*ring), node);
@@ -244,10 +251,22 @@ static int xgbe_alloc_channels(struct xgbe_prv_data *pdata)
 		netif_dbg(pdata, drv, pdata->netdev,
 			  "%s: cpu=%u, node=%d\n", channel->name, cpu, node);
 
+#ifndef CONFIG_BAIKAL_XGBE
 		netif_dbg(pdata, drv, pdata->netdev,
 			  "%s: dma_regs=%p, dma_irq=%d, tx=%p, rx=%p\n",
 			  channel->name, channel->dma_regs, channel->dma_irq,
 			  channel->tx_ring, channel->rx_ring);
+#else
+		netif_dbg(pdata, drv, pdata->netdev,
+			  "%s: dma_regs=%p, tx_dma_irq=%d, tx=%p, rx=%p\n",
+			  channel->name, channel->dma_regs, channel->tx_dma_irq,
+			  channel->tx_ring, channel->rx_ring);
+
+		netif_dbg(pdata, drv, pdata->netdev,
+			  "%s: dma_regs=%p, rx_dma_irq=%d, tx=%p, rx=%p\n",
+			  channel->name, channel->dma_regs, channel->rx_dma_irq,
+			  channel->tx_ring, channel->rx_ring);
+#endif
 	}
 
 	pdata->channel_count = count;
@@ -623,10 +642,16 @@ static irqreturn_t xgbe_dma_isr(int irq, void *data)
 	 */
 	if (napi_schedule_prep(&channel->napi)) {
 		/* Disable Tx and Rx interrupts */
+#ifndef CONFIG_BAIKAL_XGBE
 		if (pdata->channel_irq_mode)
 			xgbe_disable_rx_tx_int(pdata, channel);
 		else
 			disable_irq_nosync(channel->dma_irq);
+#else
+		xgbe_disable_rx_tx_int(pdata, channel);
+		disable_irq_nosync(channel->tx_dma_irq);
+		disable_irq_nosync(channel->rx_dma_irq);
+#endif
 
 		/* Turn on polling */
 		__napi_schedule_irqoff(&channel->napi);
@@ -654,10 +679,17 @@ static void xgbe_tx_timer(struct timer_list *t)
 	if (napi_schedule_prep(napi)) {
 		/* Disable Tx and Rx interrupts */
 		if (pdata->per_channel_irq)
+#ifndef CONFIG_BAIKAL_XGBE
 			if (pdata->channel_irq_mode)
 				xgbe_disable_rx_tx_int(pdata, channel);
 			else
 				disable_irq_nosync(channel->dma_irq);
+#else
+		{
+				disable_irq_nosync(channel->tx_dma_irq);
+				disable_irq_nosync(channel->rx_dma_irq);
+		}
+#endif
 		else
 			xgbe_disable_rx_tx_ints(pdata);
 
@@ -1015,6 +1047,7 @@ static int xgbe_request_irqs(struct xgbe_prv_data *pdata)
 	if (!pdata->per_channel_irq)
 		return 0;
 
+#ifndef CONFIG_BAIKAL_XGBE
 	for (i = 0; i < pdata->channel_count; i++) {
 		channel = pdata->channel[i];
 		snprintf(channel->dma_irq_name,
@@ -1035,6 +1068,61 @@ static int xgbe_request_irqs(struct xgbe_prv_data *pdata)
 				      &channel->affinity_mask);
 	}
 
+	err_dma_irq:
+		/* Using an unsigned int, 'i' will go to UINT_MAX and exit */
+		for (i--; i < pdata->channel_count; i--) {
+			channel = pdata->channel[i];
+
+			irq_set_affinity_hint(channel->dma_irq, NULL);
+			devm_free_irq(pdata->dev, channel->dma_irq, channel);
+		}
+
+		if (pdata->vdata->ecc_support && (pdata->dev_irq != pdata->ecc_irq))
+			devm_free_irq(pdata->dev, pdata->ecc_irq, pdata);
+
+	err_dev_irq:
+		devm_free_irq(pdata->dev, pdata->dev_irq, pdata);
+
+		return ret;
+#else
+	for (i = 0; i < pdata->channel_count; i++) {
+		channel = pdata->channel[i];
+		/* Tx */
+		snprintf(channel->tx_dma_irq_name,
+			 sizeof(channel->tx_dma_irq_name) - 1,
+			 "%s-Tx-%u", netdev_name(netdev),
+			 channel->queue_index);
+
+		ret = devm_request_irq(pdata->dev, channel->tx_dma_irq,
+				       xgbe_dma_isr, 0,
+				       channel->tx_dma_irq_name, channel);
+		if (ret) {
+			netdev_alert(netdev, "error requesting irq %d\n",
+				     channel->tx_dma_irq);
+			goto err_dma_irq;
+		}
+
+		irq_set_affinity_hint(channel->tx_dma_irq,
+						      &channel->affinity_mask);
+
+		/* Rx */
+		snprintf(channel->rx_dma_irq_name,
+			 sizeof(channel->rx_dma_irq_name) - 1,
+			 "%s-Rx-%u", netdev_name(netdev),
+			 channel->queue_index);
+
+		ret = devm_request_irq(pdata->dev, channel->rx_dma_irq,
+				       xgbe_dma_isr, 0,
+				       channel->rx_dma_irq_name, channel);
+		if (ret) {
+			netdev_alert(netdev, "error requesting irq %d\n",
+				     channel->rx_dma_irq);
+			goto err_dma_irq;
+		}
+
+		irq_set_affinity_hint(channel->rx_dma_irq,
+						      &channel->affinity_mask);
+	}
 	return 0;
 
 err_dma_irq:
@@ -1042,8 +1130,10 @@ static int xgbe_request_irqs(struct xgbe_prv_data *pdata)
 	for (i--; i < pdata->channel_count; i--) {
 		channel = pdata->channel[i];
 
-		irq_set_affinity_hint(channel->dma_irq, NULL);
-		devm_free_irq(pdata->dev, channel->dma_irq, channel);
+		devm_free_irq(pdata->dev, channel->tx_dma_irq, channel);
+		devm_free_irq(pdata->dev, channel->rx_dma_irq, channel);
+		irq_set_affinity_hint(channel->tx_dma_irq, NULL);
+		irq_set_affinity_hint(channel->rx_dma_irq, NULL);
 	}
 
 	if (pdata->vdata->ecc_support && (pdata->dev_irq != pdata->ecc_irq))
@@ -1053,6 +1143,7 @@ static int xgbe_request_irqs(struct xgbe_prv_data *pdata)
 	devm_free_irq(pdata->dev, pdata->dev_irq, pdata);
 
 	return ret;
+#endif
 }
 
 static void xgbe_free_irqs(struct xgbe_prv_data *pdata)
@@ -1071,8 +1162,15 @@ static void xgbe_free_irqs(struct xgbe_prv_data *pdata)
 	for (i = 0; i < pdata->channel_count; i++) {
 		channel = pdata->channel[i];
 
+#ifndef CONFIG_BAIKAL_XGBE
 		irq_set_affinity_hint(channel->dma_irq, NULL);
 		devm_free_irq(pdata->dev, channel->dma_irq, channel);
+#else
+		irq_set_affinity_hint(channel->tx_dma_irq, NULL);
+		irq_set_affinity_hint(channel->rx_dma_irq, NULL);
+		devm_free_irq(pdata->dev, channel->tx_dma_irq, channel);
+		devm_free_irq(pdata->dev, channel->rx_dma_irq, channel);
+#endif
 	}
 }
 
@@ -1153,10 +1251,14 @@ static void xgbe_free_rx_data(struct xgbe_prv_data *pdata)
 
 static int xgbe_phy_reset(struct xgbe_prv_data *pdata)
 {
+#ifndef CONFIG_BAIKAL_XGBE
 	pdata->phy_link = -1;
 	pdata->phy_speed = SPEED_UNKNOWN;
 
 	return pdata->phy_if.phy_reset(pdata);
+#else
+	return 0;
+#endif
 }
 
 int xgbe_powerdown(struct net_device *netdev, unsigned int caller)
@@ -2148,7 +2250,12 @@ static void xgbe_poll_controller(struct net_device *netdev)
 	if (pdata->per_channel_irq) {
 		for (i = 0; i < pdata->channel_count; i++) {
 			channel = pdata->channel[i];
+#ifndef CONFIG_BAIKAL_XGBE
 			xgbe_dma_isr(channel->dma_irq, channel);
+#else
+			xgbe_dma_isr(channel->tx_dma_irq, channel);
+			xgbe_dma_isr(channel->rx_dma_irq, channel);
+#endif
 		}
 	} else {
 		disable_irq(pdata->dev_irq);
@@ -2679,10 +2786,16 @@ static int xgbe_one_poll(struct napi_struct *napi, int budget)
 	/* If we processed everything, we are done */
 	if ((processed < budget) && napi_complete_done(napi, processed)) {
 		/* Enable Tx and Rx interrupts */
+#ifndef CONFIG_BAIKAL_XGBE
 		if (pdata->channel_irq_mode)
 			xgbe_enable_rx_tx_int(pdata, channel);
 		else
 			enable_irq(channel->dma_irq);
+#else
+		xgbe_enable_rx_tx_int(pdata, channel);
+		enable_irq(channel->tx_dma_irq);
+		enable_irq(channel->rx_dma_irq);
+#endif
 	}
 
 	DBGPR("<--xgbe_one_poll: received = %d\n", processed);
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-main.c b/drivers/net/ethernet/amd/xgbe/xgbe-main.c
index a218dc6f2edd..88a735687fc8 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-main.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-main.c
@@ -121,6 +121,9 @@
 #include <linux/etherdevice.h>
 #include <linux/io.h>
 #include <linux/notifier.h>
+#ifdef CONFIG_BAIKAL_XGBE
+#include <linux/clk.h>
+#endif
 
 #include "xgbe.h"
 #include "xgbe-common.h"
@@ -141,7 +144,11 @@ static void xgbe_default_config(struct xgbe_prv_data *pdata)
 	DBGPR("-->xgbe_default_config\n");
 
 	pdata->blen = DMA_SBMR_BLEN_64;
-	pdata->pbl = DMA_PBL_128;
+#ifdef CONFIG_BAIKAL_XGBE
+	pdata->pbl = DMA_PBL_16;
+#else
+	pdata->pbl = DMA_PBL_256;
+#endif
 	pdata->aal = 1;
 	pdata->rd_osr_limit = 8;
 	pdata->wr_osr_limit = 8;
@@ -328,6 +335,19 @@ int xgbe_config_netdev(struct xgbe_prv_data *pdata)
 	XGMAC_SET_BITS(pdata->rss_options, MAC_RSSCR, TCP4TE, 1);
 	XGMAC_SET_BITS(pdata->rss_options, MAC_RSSCR, UDP4TE, 1);
 
+#ifdef CONFIG_BAIKAL_XGBE
+	ret = clk_prepare_enable(pdata->sysclk);
+	if (ret) {
+		netdev_alert(netdev, "gmac clk_prepare_enable failed\n");
+		return ret;
+	}
+
+	ret = clk_prepare_enable(pdata->ptpclk);
+	if (ret) {
+		netdev_alert(netdev, "dma clk_prepare_enable failed\n");
+		return ret;
+	}
+#endif
 	/* Call MDIO/PHY initialization routine */
 	pdata->debugfs_an_cdr_workaround = pdata->vdata->an_cdr_workaround;
 	ret = pdata->phy_if.phy_init(pdata);
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-platform.c b/drivers/net/ethernet/amd/xgbe/xgbe-platform.c
index 4ebd2410185a..f3d50ad35689 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-platform.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-platform.c
@@ -370,6 +370,7 @@ static int xgbe_platform_probe(struct platform_device *pdev)
 	if (netif_msg_probe(pdata))
 		dev_dbg(dev, "xpcs_regs  = %p\n", pdata->xpcs_regs);
 
+#ifndef CONFIG_BAIKAL_XGBE
 	pdata->rxtx_regs = devm_platform_ioremap_resource(phy_pdev,
 							  phy_memnum++);
 	if (IS_ERR(pdata->rxtx_regs)) {
@@ -399,6 +400,7 @@ static int xgbe_platform_probe(struct platform_device *pdev)
 	}
 	if (netif_msg_probe(pdata))
 		dev_dbg(dev, "sir1_regs  = %p\n", pdata->sir1_regs);
+#endif
 
 	/* Retrieve the MAC address */
 	ret = device_property_read_u8_array(dev, XGBE_MAC_ADDR_PROPERTY,
@@ -425,7 +427,11 @@ static int xgbe_platform_probe(struct platform_device *pdev)
 	/* Check for per channel interrupt support */
 	if (device_property_present(dev, XGBE_DMA_IRQS_PROPERTY)) {
 		pdata->per_channel_irq = 1;
+#ifndef CONFIG_BAIKAL_XGBE
 		pdata->channel_irq_mode = XGBE_IRQ_MODE_EDGE;
+#else
+		pdata->channel_irq_mode = XGBE_IRQ_MODE_LEVEL;
+#endif
 	}
 
 	/* Obtain device settings unique to ACPI/OF */
@@ -467,8 +473,12 @@ static int xgbe_platform_probe(struct platform_device *pdev)
 	if (ret < 0)
 		goto err_io;
 	pdata->dev_irq = ret;
+#ifdef CONFIG_BAIKAL_XGBE
+	pdata->an_irq = pdata->dev_irq;
+#endif
 
 	/* Get the per channel DMA interrupts */
+#ifndef CONFIG_BAIKAL_XGBE
 	if (pdata->per_channel_irq) {
 		unsigned int i, max = ARRAY_SIZE(pdata->channel_irq);
 
@@ -484,12 +494,39 @@ static int xgbe_platform_probe(struct platform_device *pdev)
 
 		pdata->irq_count += max;
 	}
+#else
+	if (pdata->per_channel_irq) {
+		int i;	
+		unsigned int max = ARRAY_SIZE(pdata->channel_tx_irq);
+
+		/* Tx */
+		for (i = 0; i < pdata->tx_max_channel_count; ++i) {
+			ret = platform_get_irq(pdata->platdev, i + 1);
+			if (ret < 0)
+				goto err_io;
+			pdata->channel_tx_irq[i] = ret;	
+		}
+
+		/* Rx */
+		for (i = 0; i < pdata->rx_max_channel_count; ++i) {
+			ret = platform_get_irq(pdata->platdev, i + 9);
+			if (ret < 0)
+				goto err_io;
+			pdata->channel_rx_irq[i] = ret;	
+		}	
+
+		pdata->channel_irq_count = max;
+		pdata->irq_count += max;
+	}
+#endif
 
+#ifndef CONFIG_BAIKAL_XGBE
 	/* Get the auto-negotiation interrupt */
 	ret = platform_get_irq(phy_pdev, phy_irqnum++);
 	if (ret < 0)
 		goto err_io;
 	pdata->an_irq = ret;
+#endif
 
 	/* Configure the netdev resource */
 	ret = xgbe_config_netdev(pdata);
@@ -573,7 +610,11 @@ static int xgbe_platform_resume(struct device *dev)
 #endif /* CONFIG_PM_SLEEP */
 
 static const struct xgbe_version_data xgbe_v1 = {
+#ifdef CONFIG_BAIKAL_XGBE
+	.init_function_ptrs_phy_impl	= xgbe_init_function_ptrs_phy_baikal,
+#else
 	.init_function_ptrs_phy_impl	= xgbe_init_function_ptrs_phy_v1,
+#endif
 	.xpcs_access			= XGBE_XPCS_ACCESS_V1,
 	.tx_max_fifo_size		= 81920,
 	.rx_max_fifo_size		= 81920,
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe.h b/drivers/net/ethernet/amd/xgbe/xgbe.h
index 3305979a9f7c..450b212931b9 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@ -208,6 +208,9 @@
 #define XGBE_SPEEDSET_PROPERTY	"amd,speed-set"
 
 /* Device-tree clock names */
+#ifdef CONFIG_BAIKAL_XGBE
+#define XGBE_AXI_CLOCK          "axi"
+#endif
 #define XGBE_DMA_CLOCK		"dma_clk"
 #define XGBE_PTP_CLOCK		"ptp_clk"
 
@@ -502,8 +505,15 @@ struct xgbe_channel {
 	void __iomem *dma_regs;
 
 	/* Per channel interrupt irq number */
+#ifndef CONFIG_BAIKAL_XGBE
 	int dma_irq;
 	char dma_irq_name[IFNAMSIZ + 32];
+#else
+	int rx_dma_irq;
+	int tx_dma_irq;
+	char rx_dma_irq_name[IFNAMSIZ + 32];
+	char tx_dma_irq_name[IFNAMSIZ + 32];
+#endif
 
 	/* Netdev related settings */
 	struct napi_struct napi;
@@ -1023,6 +1033,11 @@ struct xgbe_prv_data {
 	struct platform_device *phy_platdev;
 	struct device *phy_dev;
 
+#ifdef CONFIG_BAIKAL_XGBE
+	/* phydevice - tranciever */
+	struct phy_device *phydev;
+#endif
+
 	/* Version related data */
 	struct xgbe_version_data *vdata;
 
@@ -1081,6 +1096,10 @@ struct xgbe_prv_data {
 	int ecc_irq;
 	int i2c_irq;
 	int channel_irq[XGBE_MAX_DMA_CHANNELS];
+#ifdef CONFIG_BAIKAL_XGBE
+	int channel_tx_irq[XGBE_MAX_DMA_CHANNELS];
+	int channel_rx_irq[XGBE_MAX_DMA_CHANNELS];
+#endif
 
 	unsigned int per_channel_irq;
 	unsigned int irq_count;
@@ -1315,6 +1334,10 @@ const struct udp_tunnel_nic_info *xgbe_get_udp_tunnel_info(void);
 const struct dcbnl_rtnl_ops *xgbe_get_dcbnl_ops(void);
 #endif
 
+#ifdef CONFIG_BAIKAL_XGBE
+void xgbe_init_function_ptrs_phy_baikal(struct xgbe_phy_if *);
+#endif
+
 void xgbe_ptp_register(struct xgbe_prv_data *);
 void xgbe_ptp_unregister(struct xgbe_prv_data *);
 void xgbe_dump_tx_desc(struct xgbe_prv_data *, struct xgbe_ring *,
-- 
2.33.0

